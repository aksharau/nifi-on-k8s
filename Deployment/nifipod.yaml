apiVersion: v1
kind: Pod
metadata:
  annotations:
    security.alpha.kubernetes.io/sysctls: net.ipv4.ip_local_port_range=10000 65000
  creationTimestamp: "2022-09-13T10:43:41Z"
  generateName: myrel-nifi-
  labels:
    app: nifi
    chart: nifi-1.1.1
    controller-revision-hash: myrel-nifi-c95cf679b
    heritage: Helm
    release: myrel
    statefulset.kubernetes.io/pod-name: myrel-nifi-0
  name: myrel-nifi-0
  namespace: default
  ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: StatefulSet
      name: myrel-nifi
      uid: 29244753-6f16-4cab-a417-5feed6936527
  resourceVersion: "28382"
  uid: 79ff7a81-bfc4-4a1f-a1c0-2f8c2fa1cbf2
spec:
  affinity:
    podAntiAffinity:
      preferredDuringSchedulingIgnoredDuringExecution:
        - podAffinityTerm:
            labelSelector:
              matchExpressions:
                - key: app
                  operator: In
                  values:
                    - nifi
            topologyKey: kubernetes.io/hostname
          weight: 1
  containers:
    - command:
        - bash
        - -ce
        - "prop_replace () {\n  target_file=${NIFI_HOME}/conf/${3:-nifi.properties}\n
          \ echo \"updating ${1} in ${target_file}\"\n  if egrep \"^${1}=\" ${target_file}
          &> /dev/null; then\n    sed -i -e \"s|^$1=.*$|$1=$2|\"  ${target_file}\n  else\n
          \   echo ${1}=${2} >> ${target_file}\n  fi\n}\nmkdir -p ${NIFI_HOME}/config-data/conf\nFQDN=$(hostname
          -f)\n\ncat \"${NIFI_HOME}/conf/nifi.temp\" > \"${NIFI_HOME}/conf/nifi.properties\"\nbin/nifi.sh
          set-single-user-credentials admin admin\n\n\nif ! test -f /opt/nifi/data/flow.xml.gz
          && test -f /opt/nifi/data/flow.xml; then\n  gzip /opt/nifi/data/flow.xml\nfi\n\n\nprop_replace
          nifi.remote.input.host ${FQDN}\nprop_replace nifi.cluster.node.address ${FQDN}\nprop_replace
          nifi.zookeeper.connect.string ${NIFI_ZOOKEEPER_CONNECT_STRING}\nprop_replace
          nifi.web.http.host ${FQDN}\nprop_replace nifi.web.proxy.host myrel-nifi.default.svc\n\nif
          [ ! -r \"${NIFI_HOME}/conf/nifi-cert.pem\" ]\nthen\n  /opt/nifi/nifi-toolkit-current/bin/tls-toolkit.sh
          standalone \\\n    -n 'myrel-nifi-0.myrel-nifi-headless.default.svc.cluster.local'
          \\\n    -C 'CN=admin, OU=NIFI' \\\n    -o \"${NIFI_HOME}/conf/\" \\\n    -P
          changeMe \\\n    -S changeMe \\\n    --nifiPropertiesFile /opt/nifi/nifi-current/conf/nifi.properties\nfi\nprop_replace
          nifi.web.http.network.interface.default \"eth0\" nifi.properties\nprop_replace
          nifi.web.http.network.interface.lo \"lo\" nifi.properties\n\nfor f in \"${NIFI_HOME}/conf/authorizers.xml\"
          \"${NIFI_HOME}/conf/login-identity-providers.xml\" ${NIFI_HOME}/conf/nifi.properties\ndo\n
          \ echo === $f ===\n  cat $f\ndone\necho === end of files ===\n\nfunction prop
          () {\n  target_file=${NIFI_HOME}/conf/nifi.properties\n  egrep \"^${1}=\" ${target_file}
          | cut -d'=' -f2\n}\n\nfunction offloadNode() {\n    FQDN=$(hostname -f)\n    echo
          \"disconnecting node '$FQDN'\"\n    baseUrl=https://${FQDN}:8443\n\n    echo
          \"keystoreType=$(prop nifi.security.keystoreType)\" > secure.properties\n    echo
          \"keystore=$(prop nifi.security.keystore)\" >> secure.properties\n    echo \"keystorePasswd=$(prop
          nifi.security.keystorePasswd)\" >> secure.properties\n    echo \"truststoreType=$(prop
          nifi.security.truststoreType)\" >> secure.properties\n    echo \"truststore=$(prop
          nifi.security.truststore)\" >> secure.properties\n    echo \"truststorePasswd=$(prop
          nifi.security.truststorePasswd)\" >> secure.properties\n    echo \"proxiedEntity=CN=admin,
          OU=NIFI\" >> secure.properties\n   \n    secureArgs=\"-p secure.properties\"\n\n
          \   echo baseUrl ${baseUrl}\n    echo \"gracefully disconnecting node '$FQDN'
          from cluster\"\n    ${NIFI_TOOLKIT_HOME}/bin/cli.sh nifi get-nodes -ot json
          -u ${baseUrl} ${secureArgs} > nodes.json\n    nnid=$(jq --arg FQDN \"$FQDN\"
          '.cluster.nodes[] | select(.address==$FQDN) | .nodeId' nodes.json)\n    echo
          \"disconnecting node ${nnid}\"\n    ${NIFI_TOOLKIT_HOME}/bin/cli.sh nifi disconnect-node
          -nnid $nnid -u ${baseUrl} ${secureArgs}\n    echo \"\"\n    echo \"get a connected
          node\"\n    connectedNode=$(jq -r 'first(.cluster.nodes|=sort_by(.address)|
          .cluster.nodes[] | select(.status==\"CONNECTED\")) | .address' nodes.json)\n
          \   baseUrl=https://${connectedNode}:8443\n    echo baseUrl ${baseUrl}\n    echo
          \"\"\n    echo \"wait until node has state 'DISCONNECTED'\"\n    while [[ \"${node_state}\"
          != \"DISCONNECTED\" ]]; do\n        sleep 1\n        ${NIFI_TOOLKIT_HOME}/bin/cli.sh
          nifi get-nodes -ot json -u ${baseUrl} ${secureArgs} > nodes.json\n        node_state=$(jq
          -r --arg FQDN \"$FQDN\" '.cluster.nodes[] | select(.address==$FQDN) | .status'
          nodes.json)\n        echo \"state is '${node_state}'\"\n    done\n    echo \"\"\n
          \   echo \"node '${nnid}' was disconnected\"\n    echo \"offloading node\"\n
          \   ${NIFI_TOOLKIT_HOME}/bin/cli.sh nifi offload-node -nnid $nnid -u ${baseUrl}
          ${secureArgs}\n    echo \"\"\n    echo \"wait until node has state 'OFFLOADED'\"\n
          \   while [[ \"${node_state}\" != \"OFFLOADED\" ]]; do\n        sleep 1\n        ${NIFI_TOOLKIT_HOME}/bin/cli.sh
          nifi get-nodes -ot json -u ${baseUrl} ${secureArgs} > nodes.json\n        node_state=$(jq
          -r --arg FQDN \"$FQDN\" '.cluster.nodes[] | select(.address==$FQDN) | .status'
          nodes.json)\n        echo \"state is '${node_state}'\"\n    done\n}\n\ndeleteNode()
          {\n    echo \"deleting node\"\n    ${NIFI_TOOLKIT_HOME}/bin/cli.sh nifi delete-node
          -nnid ${nnid} -u ${baseUrl} ${secureArgs}\n    echo \"node deleted\"\n}\n\nexecuteTrap()
          {\n   echo Received trapped signal, beginning shutdown...;\n   ./bin/nifi.sh
          stop;\n   exit 0;\n}\n\ntrap executeTrap TERM HUP INT;\ntrap \":\" EXIT\n\nexec
          bin/nifi.sh run & nifi_pid=\"$!\"\necho NiFi running with PID ${nifi_pid}.\nwait
          ${nifi_pid}\n"
      env:
        - name: NIFI_ZOOKEEPER_CONNECT_STRING
          value: myrel-zookeeper:2181
        - name: NIFI_WEB_HTTPS_HOST
          value: 0.0.0.0
      image: apache/nifi:1.16.3
      imagePullPolicy: IfNotPresent
      livenessProbe:
        failureThreshold: 3
        initialDelaySeconds: 90
        periodSeconds: 60
        successThreshold: 1
        tcpSocket:
          port: 8443
        timeoutSeconds: 1
      name: server
      ports:
        - containerPort: 8443
          name: https
          protocol: TCP
        - containerPort: 6007
          name: cluster
          protocol: TCP
      resources: {}
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
        - mountPath: /opt/nifi/nifi-current/logs
          name: logs
        - mountPath: /opt/nifi/data
          name: data
        - mountPath: /opt/nifi/nifi-current/auth-conf/
          name: auth-conf
        - mountPath: /opt/nifi/nifi-current/config-data
          name: config-data
        - mountPath: /opt/nifi/flowfile_repository
          name: flowfile-repository
        - mountPath: /opt/nifi/content_repository
          name: content-repository
        - mountPath: /opt/nifi/provenance_repository
          name: provenance-repository
        - mountPath: /opt/nifi/nifi-current/conf/bootstrap.conf
          name: bootstrap-conf
          subPath: bootstrap.conf
        - mountPath: /opt/nifi/nifi-current/conf/nifi.temp
          name: nifi-properties
          subPath: nifi.temp
        - mountPath: /opt/nifi/nifi-current/conf/authorizers.temp
          name: authorizers-temp
          subPath: authorizers.temp
        - mountPath: /opt/nifi/nifi-current/conf/bootstrap-notification-services.xml
          name: bootstrap-notification-services-xml
          subPath: bootstrap-notification-services.xml
        - mountPath: /opt/nifi/nifi-current/conf/login-identity-providers-ldap.xml
          name: login-identity-providers-ldap-xml
          subPath: login-identity-providers-ldap.xml
        - mountPath: /opt/nifi/nifi-current/conf/state-management.xml
          name: state-management-xml
          subPath: state-management.xml
        - mountPath: /opt/nifi/nifi-current/conf/zookeeper.properties
          name: zookeeper-properties
          subPath: zookeeper.properties
        - mountPath: /opt/nifi/data/flow.xml
          name: flow-content
          subPath: flow.xml
        - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
          name: kube-api-access-42m97
          readOnly: true
    - args:
        - /bin/sh
        - -c
        - trap "exit 0" TERM; tail -n+1 -F /var/log/nifi-app.log & wait $!
      image: busybox:1.32.0
      imagePullPolicy: IfNotPresent
      name: app-log
      resources:
        limits:
          cpu: 50m
          memory: 50Mi
        requests:
          cpu: 10m
          memory: 10Mi
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
        - mountPath: /var/log
          name: logs
        - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
          name: kube-api-access-42m97
          readOnly: true
    - args:
        - /bin/sh
        - -c
        - trap "exit 0" TERM; tail -n+1 -F /var/log/nifi-bootstrap.log & wait $!
      image: busybox:1.32.0
      imagePullPolicy: IfNotPresent
      name: bootstrap-log
      resources:
        limits:
          cpu: 50m
          memory: 50Mi
        requests:
          cpu: 10m
          memory: 10Mi
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
        - mountPath: /var/log
          name: logs
        - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
          name: kube-api-access-42m97
          readOnly: true
    - args:
        - /bin/sh
        - -c
        - trap "exit 0" TERM; tail -n+1 -F /var/log/nifi-user.log & wait $!
      image: busybox:1.32.0
      imagePullPolicy: IfNotPresent
      name: user-log
      resources:
        limits:
          cpu: 50m
          memory: 50Mi
        requests:
          cpu: 10m
          memory: 10Mi
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
        - mountPath: /var/log
          name: logs
        - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
          name: kube-api-access-42m97
          readOnly: true
  dnsPolicy: ClusterFirst
  enableServiceLinks: true
  hostname: myrel-nifi-0
  nodeName: gke-cluster-1-default-pool-cb1adeba-xjld
  preemptionPolicy: PreemptLowerPriority
  priority: 0
  restartPolicy: Always
  schedulerName: default-scheduler
  securityContext:
    fsGroup: 1000
    runAsUser: 1000
  serviceAccount: default
  serviceAccountName: default
  subdomain: myrel-nifi-headless
  terminationGracePeriodSeconds: 30
  tolerations:
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
      tolerationSeconds: 300
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
      tolerationSeconds: 300
  volumes:
    - name: logs
      persistentVolumeClaim:
        claimName: logs-myrel-nifi-0
    - name: config-data
      persistentVolumeClaim:
        claimName: config-data-myrel-nifi-0
    - name: data
      persistentVolumeClaim:
        claimName: data-myrel-nifi-0
    - name: flowfile-repository
      persistentVolumeClaim:
        claimName: flowfile-repository-myrel-nifi-0
    - name: content-repository
      persistentVolumeClaim:
        claimName: content-repository-myrel-nifi-0
    - name: provenance-repository
      persistentVolumeClaim:
        claimName: provenance-repository-myrel-nifi-0
    - name: auth-conf
      persistentVolumeClaim:
        claimName: auth-conf-myrel-nifi-0
    - configMap:
        defaultMode: 420
        items:
          - key: bootstrap.conf
            path: bootstrap.conf
        name: myrel-nifi-config
      name: bootstrap-conf
    - configMap:
        defaultMode: 420
        items:
          - key: nifi.properties
            path: nifi.temp
        name: myrel-nifi-config
      name: nifi-properties
    - configMap:
        defaultMode: 420
        items:
          - key: authorizers.xml
            path: authorizers.temp
        name: myrel-nifi-config
      name: authorizers-temp
    - configMap:
        defaultMode: 420
        items:
          - key: bootstrap-notification-services.xml
            path: bootstrap-notification-services.xml
        name: myrel-nifi-config
      name: bootstrap-notification-services-xml
    - configMap:
        defaultMode: 420
        items:
          - key: login-identity-providers-ldap.xml
            path: login-identity-providers-ldap.xml
        name: myrel-nifi-config
      name: login-identity-providers-ldap-xml
    - configMap:
        defaultMode: 420
        items:
          - key: state-management.xml
            path: state-management.xml
        name: myrel-nifi-config
      name: state-management-xml
    - configMap:
        defaultMode: 420
        items:
          - key: zookeeper.properties
            path: zookeeper.properties
        name: myrel-nifi-config
      name: zookeeper-properties
    - configMap:
        defaultMode: 420
        items:
          - key: flow.xml
            path: flow.xml
        name: myrel-nifi-config
      name: flow-content
    - name: kube-api-access-42m97
      projected:
        defaultMode: 420
        sources:
          - serviceAccountToken:
              expirationSeconds: 3607
              path: token
          - configMap:
              items:
                - key: ca.crt
                  path: ca.crt
              name: kube-root-ca.crt
          - downwardAPI:
              items:
                - fieldRef:
                    apiVersion: v1
                    fieldPath: metadata.namespace
                  path: namespace
status:
  conditions:
    - lastProbeTime: null
      lastTransitionTime: "2022-09-13T10:43:41Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2022-09-13T10:44:40Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2022-09-13T10:44:40Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2022-09-13T10:43:41Z"
      status: "True"
      type: PodScheduled
  containerStatuses:
    - containerID: containerd://2f99e4620eb9d6f8adf8284ad9ade055edf8a830c9728b2a8c56ca5741958475
      image: docker.io/library/busybox:1.32.0
      imageID: docker.io/library/busybox@sha256:bde48e1751173b709090c2539fdf12d6ba64e88ec7a4301591227ce925f3c678
      lastState: {}
      name: app-log
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2022-09-13T10:44:39Z"
    - containerID: containerd://586852477d2a6593f5194df0ee41e6abc02dc226da1884671a592b68f2c95216
      image: docker.io/library/busybox:1.32.0
      imageID: docker.io/library/busybox@sha256:bde48e1751173b709090c2539fdf12d6ba64e88ec7a4301591227ce925f3c678
      lastState: {}
      name: bootstrap-log
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2022-09-13T10:44:39Z"
    - containerID: containerd://058db2f28a9f9628dce84d013ce1d91338de326128cb843bb3168eccf73bcb6f
      image: docker.io/apache/nifi:1.16.3
      imageID: docker.io/apache/nifi@sha256:3685ea1da948f5cee68e69cfd919447d9a6aa51842a05aba81fb53365b4bb62f
      lastState: {}
      name: server
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2022-09-13T10:44:38Z"
    - containerID: containerd://e2ce85745b0705ef0581f454f105a2e157089ba771b4ae47b1a3d721499a0d2e
      image: docker.io/library/busybox:1.32.0
      imageID: docker.io/library/busybox@sha256:bde48e1751173b709090c2539fdf12d6ba64e88ec7a4301591227ce925f3c678
      lastState: {}
      name: user-log
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2022-09-13T10:44:39Z"
  hostIP: 10.128.0.6
  phase: Running
  podIP: 10.4.2.7
  podIPs:
    - ip: 10.4.2.7
  qosClass: Burstable
  startTime: "2022-09-13T10:43:41Z"
